# Autoencoders

## Topics covered in today's module
* Upsampling 
* Downsampling
* Encoders
* Decoders

## Main takeaways from doing today's assignment
* Autoencoders are neural networks that learn to compress and decompress data, and they can be used for various tasks, such as denoising and generation.
* Autoencoders consist of two main parts: an encoder that maps the input data to a lower-dimensional latent space, and a decoder that maps the latent space back to the original data space.
* Autoencoders can be trained using different types of loss functions and optimization algorithms, depending on the task at hand.
* The quality of the reconstructions and the learned representations depends on various factors, such as the architecture of the network, the size of the latent space, and the complexity of the data.
## Challenging, interesting, or exciting aspects of today's assignment
* The challenging aspect was to experiment with different hyperparameters and architectures to improve the quality of the generated images and the learned representations.
* The interesting aspect was to visualize the latent space and see how different digit classes are clustered in different regions, which can give insights into the structure of the data.
## Additional resources used 
ðŸ“‘["Building Autoencoders in Keras" by FranÃ§ois Chollet](https://blog.keras.io/building-autoencoders-in-keras.html)<br>
ðŸŽ¥["Autoencoders: Deep Learning with TensorFlow" by Deeplizard](https://www.youtube.com/watch?v=H1AllrJ-_30)<br>
