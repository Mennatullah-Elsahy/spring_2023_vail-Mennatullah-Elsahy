# Regression Loss Functions

## Topics covered in today's module
* Mean Squared Error
* Mean Absolute Error
* Mean Squared Logarithm Error

## Main takeaways from doing today's assignment
* Regression loss functions are used to measure the difference between predicted values and true values in regression tasks.
* Mean squared error (MSE) is a common loss function that penalizes large errors more heavily than small errors.
* Mean absolute error (MAE) is another loss function that penalizes all errors equally.
* Mean squared logarithmic error (MSLE) is a loss function that penalizes underestimation more heavily than overestimation, making it useful in certain applications.
* The choice of loss function can impact the performance of a regression model, and different loss functions may be appropriate for different applications.

## Challenging, interesting, or exciting aspects of today's assignment
* One of the challenges I faced here is trying to understand the mathematical concepts behind different loss functions, implement them in code, and evaluate their performance on real-world datasets.

* Interesting or exciting aspects were my exploration of the trade-offs between different loss functions and how they affect model performance, and my discovery of how different loss functions can be combined to create more effective models.

## Additional resources used 
ðŸ“•[Book: "Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow" by AurÃ©lien GÃ©ron (Chapter 2 & 10)](https://drive.google.com/file/d/1tAoPyJfFOt6fzi2SFGJAJArPlIKWV5gd/view)<br>
ðŸ“°[A blog post by Jason Brownlee with examples and code](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/)
